{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(data_dir):\n",
    "  \n",
    "    data = {}\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        data[split] = []\n",
    "        for sentiment in [\"neg\", \"pos\"]:\n",
    "            score = 1 if sentiment == \"pos\" else 0\n",
    "\n",
    "            path = os.path.join(data_dir, split, sentiment)\n",
    "            file_names = os.listdir(path)\n",
    "            for f_name in file_names:\n",
    "                with open(os.path.join(path, f_name), \"r\") as f:\n",
    "                    review = f.read()\n",
    "                    data[split].append([review, score])\n",
    "\n",
    "    np.random.shuffle(data[\"train\"])        \n",
    "    data[\"train\"] = pd.DataFrame(data[\"train\"],\n",
    "                                 columns=['text', 'sentiment'])\n",
    "\n",
    "    np.random.shuffle(data[\"test\"])\n",
    "    data[\"test\"] = pd.DataFrame(data[\"test\"],\n",
    "                                columns=['text', 'sentiment'])\n",
    "\n",
    "    return data[\"train\"], data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The path may vary depending on the enviroment used \n",
    "#to work with the Notebook\n",
    "#(Google Colab, Kaggle Kernel, Jupyter)\n",
    "\n",
    "train, test = data_load('aclImdb_v1/aclImdb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text should be treated as string, because by default python char array (' ') adds extra symbols for quoting, this might screw the preprocessing on the further steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([train,test], axis=0)\n",
    "\n",
    "corpus['text'] = corpus['text'].astype(str)\n",
    "\n",
    "#Clean the memory\n",
    "del train\n",
    "del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MultionomialNB with no preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus['text'], corpus['sentiment'],\n",
    "                                                   test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "X_train = vec.fit_transform(X_train)\n",
    "X_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#alpha parameters stands for Add-One(Laplace) Smooting\n",
    "model = MultinomialNB(alpha=1.0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"The F1 accuracy score: {}%\".format(f1_score(y_test, pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "The result above is good enough for raw, uncleaned data. Let's explore data, to see what kind of preprocessing steps will be crucial\n",
    "The plan for EDA is\n",
    "*  Check the word frequency to build a better stop_words list\n",
    "* Check if data is dirty with HTML\n",
    "* Check for some extra features such as emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq(bag_of_words, n):\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return np.array(words_freq[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word_freq(X_train, 30), columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Tags and Numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if dataset contains HTML Tags\n",
    "corpus[corpus['text'].str.contains(\"<br\")]['text'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoticons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there are relevant emoticons in the dataset\n",
    "\n",
    "sad_emoticon =   '[:;](.?)[\\(\\[\\{]|[\\(\\[\\{]{2,}'\n",
    "happy_emoticon = '[:;](.?)[\\)\\]\\}]|[\\)\\]\\}]{2,}'\n",
    "\n",
    "sad_in_negative = sum(corpus[corpus['text'].str.contains(sad_emoticon,\n",
    "                                       regex=True)]['sentiment']==0) \n",
    "sad_in_positive = sum(corpus[corpus['text'].str.contains(sad_emoticon,\n",
    "                                       regex=True)]['sentiment']==1)\n",
    "\n",
    "happy_in_negative = sum(corpus[corpus['text'].str.contains(happy_emoticon,\n",
    "                                       regex=True)]['sentiment']==0)\n",
    "happy_in_positive = sum(corpus[corpus['text'].str.contains(happy_emoticon,\n",
    "                                       regex=True)]['sentiment']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sad emoticon in Negative class:   {}\".format(sad_in_negative))\n",
    "print(\"Sad emoticon in Positive class:   {}\".format(sad_in_positive))\n",
    "print(\"Happy emoticon in Negative class: {}\".format(happy_in_negative))\n",
    "print(\"Happy emoticon in Positive class: {}\".format(happy_in_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(2)\n",
    "bar_width = 0.4\n",
    "rects1 = ax.bar(index, ((sad_in_negative/(sad_in_negative+sad_in_positive))*100, \n",
    "                        (sad_in_positive/(sad_in_negative+sad_in_positive))*100), \n",
    "                         bar_width, alpha=0.4, color='b',label='Sad')\n",
    "\n",
    "rects2 = ax.bar(index + bar_width, \n",
    "                ((happy_in_negative/(happy_in_negative+happy_in_positive))*100, \n",
    "                 (happy_in_positive/(happy_in_negative+happy_in_positive))*100),\n",
    "                  bar_width, alpha=0.5, color='r', label='Happy')\n",
    "\n",
    "ax.set_xlabel('Sentiment')\n",
    "ax.set_ylabel('Percentages')\n",
    "ax.set_title('Scores by sentiment and \\'happy\\' and \\'sad\\' emoticons')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(('Negative', 'Positive'))\n",
    "\n",
    "ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Goal for this stage\n",
    "* Remove HTML tags and numericals\n",
    "* Turn emoticons into corresponding codes (':)))))' -> HAPPY_EMOT)\n",
    "* Preprocess negation (Example: \"don't like this movie. awful\" -> \"don't NOT_like awful\")\n",
    "* Delete all the symbols that were not recognized as HTML, numbers, and apostrophes as part of word shortenings\n",
    "\n",
    "In between each preprocessing stage it is also important to review how they modified the text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean HTML and Numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_html(raw_text):\n",
    "  cleanr = re.compile('<.*?>|[0-9]')\n",
    "  cleantext = re.sub(cleanr, '', raw_text)\n",
    "    \n",
    "  return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['text'] = train['text'].apply(clean_html)\n",
    "#test['text'] = test['text'].apply(clean_html)\n",
    "corpus['text'] = corpus['text'].apply(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['text'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoticons\n",
    "Preprocess emoticons and convert to corresponding code representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def emoticons(raw_text):\n",
    "    #this function turns emoticons into corresponding text\n",
    "    #representation, ignoting single parenthesis \n",
    "    sad_emoticon =   re.compile('[:;](.?)[\\(\\[\\{]|[\\(\\[\\{]{2,}')\n",
    "    happy_emoticon = re.compile('[:;](.?)[\\)\\]\\}]|[\\)\\]\\}]{2,}')  \n",
    "    cleantext = re.sub(sad_emoticon, 'SAD_EMOT ', raw_text)\n",
    "    cleantext = re.sub(happy_emoticon, ' '+'HAPPY_EMOT'+' ', cleantext) \n",
    "    \n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train['text'] = train['text'].apply(emoticons)\n",
    "#test['text'] = test['text'].apply(emoticons)\n",
    "\n",
    "corpus['text'] = corpus['text'].apply(emoticons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negations\n",
    "Preprocess word negations and convert to corresponding representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edited NLTK stopwords\n",
    "\n",
    "stopWords = {'its', 'is', \"you'd\", 'was','movie',\n",
    "             'above', 'further', 'y', \"should've\",'again', 'then', 'am', 'are',\n",
    "             'their', 'being', 'does', 'no', 'over', 'them',  'her', 'for', 'after',\n",
    "             'yourselves', 'both', 'before', 'now', 'should', 'too',\n",
    "             'yourself', 'here', 'same', 'do', 'our', 'has', 'all', \"you'll\",\n",
    "             'only', 'as', 'my', 'any',\"that'll\", 'i', 'when', 'by', 'than', 'had',\n",
    "             'your', \"you're\", 'can', 'be', 'herself','myself', 'at',  'in', 'during',\n",
    "             'did', 'me', 'who', 'own', 'ours', 'won', 'up',\"it's\", 'that', 'but', 'those', \n",
    "             'so', 'an', 'whom', 'shan', 'himself','very','about', 'from', 'which', 'once', \n",
    "             'where', 'his', 'few', 'these', 'each', 'other','most',  \"she's\", 're', 'a',\n",
    "             'him', 'the', 'under', 'd', 'there', 'we', 'having', 'into', 'you',  \n",
    "             'between', 's', 'o', 'itself', 'below', 'll', 'were', 'they', 'how', 'through',\n",
    "             \"you've\", 'ourselves', 'until', 'to', 'theirs', 'against', 'themselves', 'and',\n",
    "             'ma', 'or', 'off', 'because', 'on',  'such',  'what',  'out', 'with', 'just',\n",
    "             'doing', 'he', 'it', 'why', 't', 'yours',  'some', 've', 'if', 'will', 'hers',\n",
    "             'while', 'she','been', 'of', 'more', 'nor', 'this', 'm','have', 'down'}\n",
    "\n",
    "negateWords = {'ain', 'don', \"don't\",\n",
    "               'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\",'doesn', \"doesn't\",\n",
    "               'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'mightn',\n",
    "               \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'not', \"shan't\", 'shouldn',\n",
    "               \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \"won't\", 'wouldn',\"wouldn't\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negate_sequence(text):\n",
    "    \"\"\"\n",
    "    Detects negations and transforms negated words into \"NOT_\" form \n",
    "    for all words until the next punctuation mark.\n",
    "    \"\"\"\n",
    "    negation = False\n",
    "    delims = \"?.,!:;'\\\"\"\n",
    "    result = []\n",
    "#Here rather then applying split, we can directly feed our extracted symptoms list\n",
    "    words = text.lower().split()\n",
    "    prev = None\n",
    "    pprev = None\n",
    "    for word in words:\n",
    "        #stripped = word.strip(delchars)\n",
    "        stripped = word.strip(delims)\n",
    "        if stripped not in stopWords:\n",
    "            negated = \"NOT_\" + stripped if negation else stripped\n",
    "            if negated not in negateWords:\n",
    "                result.append(negated)\n",
    "        \n",
    "        if any(neg in word for neg in ['NOT','not','N\\'T', 'n\\'t','nt','NT']):\n",
    "            negation = not negation\n",
    "\n",
    "        if any(c in word for c in delims):\n",
    "            negation = False\n",
    "\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['text'].head().apply(negate_sequence).iloc[1]\n",
    "#test['text'] = test['text'].apply(negate_sequence)\n",
    "\n",
    "corpus['text'] = corpus['text'].apply(negate_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['text'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbols\n",
    "Clean data from extra symbols that were not cleaned on earlier stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preproc(raw_text):\n",
    "    cleanr = re.compile('[\\-\\+!@#$%^&*()<>?\\|\\/]')\n",
    "    cleantext = re.sub(cleanr, '', raw_text)\n",
    "    \n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['text'] = train['text'].apply(preproc)\n",
    "#test['text'] = test['text'].apply(preproc)\n",
    "\n",
    "corpus['text'] = corpus['text'].apply(preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNetLemmatizer\n",
    "Lemmatize the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()\n",
    "def lemmatize_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    lemmatized_tokens = [lmtzr.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['text'] = train['text'].apply(lemmatize_sentences)\n",
    "#test['text'] = test['text'].apply(lemmatize_sentences)\n",
    "\n",
    "corpus['text'] = corpus['text'].apply(lemmatize_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['text'].iloc[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter Stemmer (SKIP)\n",
    "For this particular dataset the PorterStemmer does not bring better performance, so it is better to skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split()\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus['text'] = corpus['text'].apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['text'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram_range 1,3 brings highest accuracy score, \n",
    "#yet it is very slow to train\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus['text'], corpus['sentiment'],\n",
    "                                                   test_size=0.25)\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1,3),\n",
    "                      binary=True)\n",
    "X_train = vec.fit_transform(X_train)\n",
    "X_test = vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB training and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=1.0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print(\"The F1 accuracy score: {}%\".format(f1_score(y_test, pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC Training and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = LinearSVC(C=4,loss='squared_hinge')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print(\"The F1 accuracy score: {}%\".format(f1_score(y_test, pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
