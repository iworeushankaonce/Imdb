{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKb3hD5S8pt0"
   },
   "outputs": [],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "!tar -zxvf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ab36Il69-K7D"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac_8o7HmAH0a"
   },
   "outputs": [],
   "source": [
    "def data_load(data_dir):\n",
    "  \n",
    "    data = {}\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        data[split] = []\n",
    "        for sentiment in [\"neg\", \"pos\"]:\n",
    "            score = 1 if sentiment == \"pos\" else 0\n",
    "\n",
    "            path = os.path.join(data_dir, split, sentiment)\n",
    "            file_names = os.listdir(path)\n",
    "            for f_name in file_names:\n",
    "                with open(os.path.join(path, f_name), \"r\") as f:\n",
    "                    review = f.read()\n",
    "                    data[split].append([review, score])\n",
    "\n",
    "    np.random.shuffle(data[\"train\"])        \n",
    "    data[\"train\"] = pd.DataFrame(data[\"train\"],\n",
    "                                 columns=['text', 'sentiment'])\n",
    "\n",
    "    np.random.shuffle(data[\"test\"])\n",
    "    data[\"test\"] = pd.DataFrame(data[\"test\"],\n",
    "                                columns=['text', 'sentiment'])\n",
    "\n",
    "    return data[\"train\"], data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slkuH2CNAICP"
   },
   "outputs": [],
   "source": [
    "train, test = data_load(\"aclImdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "TOcUYT4IMFpM",
    "outputId": "76544f9b-ea3e-47cc-c8f5-7e33643d218a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie has not aged well. Maybe it's just ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Brain That Wouldn't Die is one awful piece...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ed Wood is eclipsed and becomes Orson Welles. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Billed as a kind of sequel to The Full Monty, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First things first, Edison Chen did a fantasti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  This movie has not aged well. Maybe it's just ...          0\n",
       "1  The Brain That Wouldn't Die is one awful piece...          0\n",
       "2  Ed Wood is eclipsed and becomes Orson Welles. ...          0\n",
       "3  Billed as a kind of sequel to The Full Monty, ...          0\n",
       "4  First things first, Edison Chen did a fantasti...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing, Lemmatization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FrvpZHQAIM4"
   },
   "outputs": [],
   "source": [
    "y_train = train['sentiment']\n",
    "X_train = train.drop(['sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTXyQPnqAIfZ"
   },
   "outputs": [],
   "source": [
    "y_test = test['sentiment']\n",
    "X_test = test.drop(['sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5Y_QCpyNfXi"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def preproc(s):\n",
    "    s = re.sub(r\"\\\\\", \"\", s)    \n",
    "    s = re.sub(r\"\\'\", \"\", s)    \n",
    "    s = re.sub(r\"\\\"\", \"\", s)    \n",
    "    \n",
    "    s = s.strip().lower()\n",
    "    \n",
    "    filters='!@#$%^&*()_-+={}/\\[],.<>\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    s = s.translate(translate_map)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_PanRabAIqy"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf = TfidfVectorizer(preprocessor=preproc,\n",
    "                         analyzer='word',\n",
    "                         stop_words='english',\n",
    "                         ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AvGJa3YPkpI"
   },
   "outputs": [],
   "source": [
    "train_feat = tf_idf.fit_transform(X_train['text'])\n",
    "test_feat = tf_idf.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSZs6trRAJFQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUBBI4IHAI6_"
   },
   "outputs": [],
   "source": [
    "model = LinearSVC(C=.4, \n",
    "                  loss='squared_hinge',\n",
    "                  random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "X5FOr73QRtEF",
    "outputId": "5786a8aa-2eb8-4279-b429-e7421857add5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.4, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=13, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_feat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m28TjTP4SHo4"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MseIULN8bfsH",
    "outputId": "291bd324-3ecf-4417-a2b3-2ad36059d8aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.47%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, pred)*100))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sentiment_polarity.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
